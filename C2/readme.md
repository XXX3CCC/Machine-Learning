## [Assignment2 description](https://github.com/XXX3CCC/Machine-Learning/blob/main/C2/Coding%20Assignment%202.pdf)

Download: Codebase

In this problem, you are asked to apply linear regression and logistics regression for binary classification. In particular, this problem shows that linear regression is a bad model for classification problems.

We consider a binary classification problem, where the input is a two-dimensional vector and the output is {0,1}. In other words,  and . Specifically, we would train our classifiers on the following two datasets:

Dataset A: 

In this dataset, positive samples are generated by a bivariate normal distribution , where  and . Negative samples are generated by another , where . The covariance is the same as the positive samples. 

We have 400 samples in total, where 200 are positive and 200 are negative. The dataset is plotted in the left panel below. 

Dataset B: We now construct a new dataset by shifting half of the positive (blue) samples to the upper right as shown in the right panel. In other words, the positive samples are generated by  and  with equal probability, where .




Dataset A
Dataset B



Questions: 

For each of Dataset A or Dataset B:
Train a classifier by thresholding a linear regression model. In other words, treat the target 0/1 labels as real numbers, and classify a sample as positive if the predicted value is greater than or equal to 0.5.  

Train a logistic regression classifier on the same data.


Submission (four numbers and four plots): 

Report the following four numbers
Training accuracy of linear regression on Dataset A 
Training accuracy of logistic regression on Dataset A
Training accuracy of linear regression on Dataset B
Training accuracy of logistic regression on Dataset B
and plot four decision boundaries. Please make clear which classifier is applied in the plot. 
 



Problem 2 [50%]

Download: Codebase

In this coding problem, we will implement the softmax regression for multi-class classification using the MNIST dataset. 

Dataset

First, download the datasets from the link above. You need to unzip the .gz file by either double clicking or some command like gunzip -k file.gz

The dataset contains 60K training samples, and 10K test samples. Again, we split 10K from the training samples for validation. In other words, we have 50K training samples, 10K validation samples, and 10K test samples. The target label is among {0, 1, …, 9}.

Algorithm

We will implement stochastic gradient descent (SGD) for cross-entroy loss of softmax as the learning algorithm. The measure of success will be the accuracy (i.e., the fraction of correct predictions).

The general framework for this coding assignment is the same as SGD for linear regression, so you may re-use most of the code. However, you shall change the computation of output, the loss function, the measure of success, and the gradient whenever needed. 


Implementation trick

For softmax classification, you may encounter numerical overflow if you just follow the equation mentioned in the lecture. 




The observation is that the exp function increases very fast with its input, and very soon exp(z) will give NAN (not a number). 

The trick is to subtract every  by the maximum value . 

In other words, we compute 
, where , and then we have



Note that the gradient is computed with y, and since subtracting a constant before softmax doesn’t affect y, it doesn’t affect the gradient either. 


[40 marks]
	Without changing the the default hyperparameters, we report three numbers: 
The number of epoch that yields the best validation performance,
The validation performance (accuracy) in that epoch, and
The test performance (accuracy) in that epoch. 
and two plots:
The learning curve of the training cross-entropy loss, and
The learning curve of the validation accuracy.


[10 marks]
Ask one meaningful scientific question yourself, design your experimental protocol, present results, and draw a conclusion. 
